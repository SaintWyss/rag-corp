services:
  db:
    image: pgvector/pgvector:0.8.1-pg16-trixie
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: rag
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
      - ./infra/postgres/init.sql:/docker-entrypoint-initdb.d/00-init.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d rag"]
      interval: 5s
      timeout: 5s
      retries: 5

  rag-api:
    build:
      context: ./backend
    environment:
      DATABASE_URL: postgresql://postgres:postgres@db:5432/rag
      # Pasamos la variable del host al contenedor
      GOOGLE_API_KEY: ${GOOGLE_API_KEY}
      FAKE_LLM: ${FAKE_LLM:-}
      FAKE_EMBEDDINGS: ${FAKE_EMBEDDINGS:-}
      REDIS_URL: ${REDIS_URL:-redis://redis:6379}
      API_KEYS_CONFIG: ${API_KEYS_CONFIG:-}
      RBAC_CONFIG: ${RBAC_CONFIG:-}
      S3_ENDPOINT_URL: ${S3_ENDPOINT_URL:-}
      S3_BUCKET: ${S3_BUCKET:-}
      S3_ACCESS_KEY: ${S3_ACCESS_KEY:-}
      S3_SECRET_KEY: ${S3_SECRET_KEY:-}
      S3_REGION: ${S3_REGION:-}
    volumes:
      - ./:/repo
    working_dir: /repo/backend
    command:
      - sh
      - -c
      - alembic upgrade head && uvicorn app.main:app --host 0.0.0.0 --port 8000
    ports:
      - "8000:8000"
    depends_on:
      db:
        condition: service_healthy
    healthcheck:
      test:
        [
          "CMD",
          "python",
          "-c",
          "import urllib.request as u; u.urlopen('http://localhost:8000/healthz')",
        ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  worker:
    build:
      context: ./backend
    environment:
      DATABASE_URL: postgresql://postgres:postgres@db:5432/rag
      GOOGLE_API_KEY: ${GOOGLE_API_KEY}
      FAKE_LLM: ${FAKE_LLM:-}
      FAKE_EMBEDDINGS: ${FAKE_EMBEDDINGS:-}
      REDIS_URL: ${REDIS_URL:-redis://redis:6379}
      API_KEYS_CONFIG: ${API_KEYS_CONFIG:-}
      RBAC_CONFIG: ${RBAC_CONFIG:-}
      S3_ENDPOINT_URL: ${S3_ENDPOINT_URL:-}
      S3_BUCKET: ${S3_BUCKET:-}
      S3_ACCESS_KEY: ${S3_ACCESS_KEY:-}
      S3_SECRET_KEY: ${S3_SECRET_KEY:-}
      S3_REGION: ${S3_REGION:-}
      WORKER_HTTP_PORT: ${WORKER_HTTP_PORT:-8001}
    volumes:
      - ./:/repo
    working_dir: /repo/backend
    command:
      - sh
      - -c
      - alembic upgrade head && python -m app.worker.worker
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
      rag-api:
        condition: service_healthy
    healthcheck:
      test:
        [
          "CMD",
          "python",
          "-c",
          "import urllib.request as u; u.urlopen('http://localhost:8001/readyz')",
        ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    profiles:
      - worker
      - full

  web:
    build:
      context: .
      dockerfile: frontend/Dockerfile
      args:
        NEXT_PUBLIC_API_URL: ${NEXT_PUBLIC_API_URL:-http://rag-api:8000}
    ports:
      - "3000:3000"
    depends_on:
      - rag-api
    profiles:
      - e2e

  # Redis cache (optional, for production)
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
    profiles:
      - cache
      - worker
      - full

  # Observability stack (optional, use --profile observability)
  prometheus:
    image: prom/prometheus:v2.47.0
    volumes:
      - ./infra/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--web.enable-lifecycle"
    ports:
      - "9090:9090"
    restart: unless-stopped
    profiles:
      - observability
      - full

  grafana:
    image: grafana/grafana:10.2.0
    volumes:
      - grafana_data:/var/lib/grafana
      - ./infra/grafana/dashboards:/var/lib/grafana/dashboards:ro
      - ./infra/grafana/provisioning-dashboards.yml:/etc/grafana/provisioning/dashboards/dashboards.yml:ro
      - ./infra/grafana/provisioning-datasources.yml:/etc/grafana/provisioning/datasources/datasources.yml:ro
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-admin}
      GF_USERS_ALLOW_SIGN_UP: "false"
    ports:
      - "3001:3000"
    depends_on:
      - prometheus
    restart: unless-stopped
    profiles:
      - observability
      - full

  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:v0.15.0
    environment:
      DATA_SOURCE_NAME: postgresql://postgres:postgres@db:5432/rag?sslmode=disable
    ports:
      - "9187:9187"
    depends_on:
      db:
        condition: service_healthy
    restart: unless-stopped
    profiles:
      - observability
      - full

  minio:
    image: minio/minio:RELEASE.2025-04-08T15-41-24Z
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin}
    volumes:
      - minio_data:/data
    ports:
      - "9000:9000"
      - "9001:9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/ready"]
      interval: 10s
      timeout: 5s
      retries: 5
    profiles:
      - storage
      - full

  minio-init:
    image: minio/mc:RELEASE.2025-04-08T15-39-49Z
    depends_on:
      minio:
        condition: service_healthy
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin}
      S3_BUCKET: ${S3_BUCKET:-rag-documents}
    entrypoint:
      - sh
      - -c
      - >
        mc alias set local http://minio:9000 "$${MINIO_ROOT_USER}" "$${MINIO_ROOT_PASSWORD}" &&
        mc mb --ignore-existing "local/$${S3_BUCKET}" &&
        mc anonymous set none "local/$${S3_BUCKET}"
    profiles:
      - storage
      - full

volumes:
  pgdata:
  redis_data:
  prometheus_data:
  grafana_data:
  minio_data:
