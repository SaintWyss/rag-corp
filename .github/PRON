@workspace
QUIERO DOCUMENTACIÓN PROFESIONAL “V3” (CREAR O ACTUALIZAR), CON VERIFICACIÓN REAL. HACÉ LOS CAMBIOS DIRECTAMENTE.

OBJETIVO
Dejar el repo con documentación clara, consistente y 100% alineada al estado real del código (v3). Si ya existe documentación, ACTUALIZALA y CORREGÍ DRIFT. Si falta, CREALA. Nada de texto genérico.

REGLAS (OBLIGATORIAS)
- CERO INVENCIÓN: cada comando, puerto, endpoint, variable env y script debe salir de archivos reales (package.json, compose.yaml, Dockerfiles, workflows, routers OpenAPI, etc.).
- Si algo no existe o no se puede verificar: poner “TODO(verify)” + explicar qué falta.
- Preferí links internos relativos (sin URLs externas).
- Mantener estilo “portal”: corto, navegable, con bullets y tablas pequeñas.
- NO cambies lógica de negocio ni arquitectura del runtime: solo documentación + ajustes mínimos de higiene de docs (links rotos, paths incorrectos).
- Antes de editar, escaneá el repo para identificar qué docs ya existen y qué está desalineado.
- Al final: validar links internos (al menos manualmente revisando rutas) y validar que los comandos referenciados existen como scripts o están en compose.
- Entrega final: reportar cambios SIN CÓDIGO + comandos de verificación que corriste + 1 commit.

TAREAS

(1) INVENTARIO + DRIFT CHECK (ANTES DE EDITAR)
- Listar qué docs ya existen (README raíz, doc/, otros .md relevantes).
- Marcar drift: 10–20 bullets de cosas que hoy están desactualizadas o incompletas, citando rutas exactas.

(2) README.md RAÍZ COMO “PORTAL” (CREAR O ACTUALIZAR)
Debe incluir, en este orden:
1) Qué es el proyecto y qué problema resuelve (3–6 bullets).
2) Features reales (solo lo implementado) — incluir: RAG, ingesta, CRUD documentos, chat streaming multi-turn, cache embeddings, RBAC, rate limit, metrics.
3) Stack (tabla corta FE/BE/DB/AI/Obs/CI).
4) Arquitectura high-level:
   - componentes y responsabilidades
   - flujo ingest → ask → chat streaming (bullets)
5) Quickstart local:
   - requisitos (node/pnpm, python, docker)
   - variables env mínimas (tabla: nombre, dónde se usa, ejemplo)
   - comandos EXACTOS (extraídos de scripts/compose)
   - cómo validar (curl /healthz, /metrics, endpoints clave)
6) Estructura del repo (carpetas principales con 1 línea cada una).
7) Links a /doc (índice).
8) Roadmap / TODOs (solo post-v3 realistas, 5–10 items).

(3) /doc (CREAR O ACTUALIZAR) — ESTRUCTURA MÍNIMA OBLIGATORIA
Asegurar que existan y estén alineados:
- doc/README.md (índice consolidado y guía de navegación)
- doc/architecture/overview.md (arquitectura + flujos + límites)
- doc/architecture/decisions/ (ADRs)
  - Si no hay ADRs: crear 2 mínimos (v3) con plantilla corta:
    - ADR-001: RBAC + API keys + scopes fallback
    - ADR-002: Embedding cache (memory/redis) + métricas hit/miss
- doc/design/patterns.md (qué patrones usa el repo y dónde, con rutas)
- doc/api/http-api.md (endpoints, payloads, errores RFC7807, auth headers, SSE streaming format)
- doc/data/postgres-schema.md (tablas/índices, pgvector, migraciones; si algo no está claro, TODO)
- doc/runbook/local-dev.md (cómo correr, troubleshooting, perfiles compose, healthchecks)
- doc/quality/testing.md (unit BE/FE, e2e Playwright + CI, k6 si existe)
- doc/diagrams/ (Mermaid)

(4) CONTENIDO MÍNIMO POR DOC (PLANTILLA)
En cada doc, incluir:
- “Purpose” (1–2 líneas)
- “How to use / run” (comandos reales o TODO)
- “How to extend” (2–5 bullets concretos)
- “References” (links internos a archivos/config del repo)

(5) DIAGRAMAS MERMAID (2–3)
Crear en doc/diagrams/:
1) component-diagram.mmd: componentes (web, rag-api, db/pgvector, redis opcional, obs) y conexiones.
2) sequence-ingest-ask.mmd: secuencia ingest + ask/query.
3) sequence-chat-stream.mmd: SSE streaming multi-turn con conversation_id.
Los diagramas deben reflejar endpoints y nombres reales.

(6) VERIFICACIÓN FINAL (OBLIGATORIA)
- Confirmar que:
  - todos los links internos apuntan a rutas reales
  - los comandos del README existen (scripts, compose, workflows) o están marcados TODO(verify)
  - endpoints mencionados existen en routers/openapi
- Si hay tool para link-checker, usarlo; si no, hacer verificación manual mínima.

(7) SALIDA + COMMIT
- Crear 1 commit: "v3: docs: professional documentation portal + /doc alignment"
- En tu respuesta final, entregar:
  - ✅/⚠️ estado general
  - lista de archivos creados/actualizados (rutas)
  - top 10 correcciones de drift hechas
  - comandos de verificación corridos (si no corriste, decir por qué)
  - TODOs explícitos que quedaron (si faltó info verificable)

DEFINICIÓN DE DONE
- README raíz sirve como portal y permite correr el proyecto sin adivinar.
- /doc tiene índice y cada doc tiene propósito + comandos reales + cómo extender.
- Mermaid diagrams existen y representan la realidad del repo.
- No hay links rotos obvios ni comandos inventados.



@workspace
QUIERO UN SOLO INFORME MAESTRO (AUDITORÍA + CONFORMIDAD + PLAN DE MEJORA + CRC), SIN MODIFICAR ARCHIVOS.

CONTEXTO
Este repo está en “v3” (fase 3). Quiero auditar si lo que tenemos respeta nuestras metodologías (Clean Architecture, SOLID, límites claros, DI/ports, contratos FE/BE, errores consistentes, observabilidad, seguridad, tests/CI) y qué mejorar SIN romper producto.

REGLAS (OBLIGATORIAS)
- NO CAMBIES EL CÓDIGO. NO CREES COMMITS. NO MODIFIQUES ARCHIVOS. Solo análisis y propuestas.
- CERO HALLUCINACIÓN: cada afirmación importante debe citar rutas/archivos exactos (ej: backend/app/... , apps/web/...).
- Si algo no lo encontrás, decí “NO ENCONTRADO” y sugerí dónde debería estar.
- Explicación “para Santiago” (estudiante Ing. Sistemas): clara, rigurosa, con bullets.
- No incluyas la “tarea de crear documentación profesional nueva”. Solo podés referenciar docs existentes para extraer comandos/checklists.
- Formato: bullets claros, secciones numeradas. Evitar texto largo sin estructura.

ENTREGABLES (EN ESTE ORDEN)

(0) SNAPSHOT DEL REPO (para ubicarnos)
- Stack detectado (FE/BE/DB/AI/CI/Obs) con evidencia (archivos clave: package.json, pyproject/requirements, compose, workflows).
- “Mapa de ejecución”: qué corre dónde (local dev / CI / e2e), con rutas a scripts.

(1) RESUMEN DE ARQUITECTURA (high-level)
- Componentes y responsabilidades (Web, API, DB/pgvector, Redis opcional, Obs, CI).
- Flujo principal (ingesta → embeddings → almacenamiento → retrieval → respuesta) y variantes (chat multi-turn + streaming SSE).
- Puntos de entrada/salida (HTTP endpoints, SSE events, DB tables) con evidencia (rutas).

(2) MAPA DE CARPETAS (por qué existe cada una)
- Tabla o bullets por carpeta principal (ej: backend/app, apps/web, infra, tests/e2e, doc, .github).
- Para cada carpeta: rol, qué contiene, qué NO debería contener, y evidencias (1–2 rutas ejemplo).

(3) EVALUACIÓN DE BUENAS PRÁCTICAS (con scorecard)
Armar una “matriz de conformidad” con ✅/⚠️/❌ y evidencia por punto:
- Separación de capas y límites (dominio/use-cases vs infra/adapters).
- SOLID (SRP, DIP especialmente) y uso de DI/ports.
- Naming/consistencia (nombres de permisos RBAC, settings, rutas).
- Manejo de errores (RFC7807 u otro): dónde se construyen, cómo se propagan, status codes consistentes.
- Tipado/contratos FE/BE (OpenAPI, orval, validación pydantic/zod si aplica) + compatibilidad.
- Configuración (env vars, settings), defaults seguros, perfiles (dev/e2e).
- Logging/observabilidad (prometheus metrics, request_id, traces si hay).
- Seguridad (API keys, RBAC, rate limit, headers, CORS, metrics auth flag).
- Tests (unit BE/FE, e2e playwright, k6) + CI (workflows, artifacts).
Incluí “qué está excelente” + “qué está riesgoso” por cada área.

(4) DEUDA TÉCNICA PRIORIZADA (Top 10, impacto alto → bajo)
- 10 issues concretos con:
  - Impacto (alto/medio/bajo) + Riesgo (seguridad/perf/mantenibilidad/UX).
  - Evidencia (rutas/archivos exactos).
  - Por qué es un problema (1–2 bullets).
  - Recomendación (1–2 bullets).
Ejemplos de categorías esperadas (no obligatorias): persistencia de conversations (in-memory), default de redis autodetect, strings sueltas de permisos, console.error en tests FE, duplicación de rutas /api/v1, hardcodes de env, etc. SOLO si lo encontrás en el repo.

(5) QUICK WINS (1–2 horas) y MEJORAS MEDIANAS (1–2 días)
- Listas separadas con pasos concretos (3–7 pasos por item).
- Cada item debe mencionar archivos afectados (rutas) y cómo probarlo (comando/script real).
- NO propongas reescrituras grandes.

(6) CHECKLIST PARA CORRER LOCAL
- Extraer de README/compose/scripts reales.
- Incluir:
  - requisitos
  - env vars mínimas
  - comandos exactos (pnpm, pytest, docker compose, e2e)
  - healthchecks y endpoints para validar (curl)
- Si hay múltiples modos (dev vs e2e), separarlos.

(7) PROPUESTA DE MEJORA DE ARQUITECTURA (SIN ROMPER PRODUCTO)
Primero, “Arquitectura objetivo” (diagrama textual):
- Límites claros: Domain / Application(Use Cases) / Infrastructure / API / UI
- Ports/Adapters para LLM, Embeddings, VectorStore, Cache, ConversationRepo
- Motivos y beneficios (2–5 bullets)
Luego, patrones propuestos y dónde aplicar (con rutas sugeridas):
- Repository, Adapter/Port, Facade, Strategy, Policy/Guard (authz), Factory/Provider, etc.
Después, PLAN EN FASES (Fase 1/2/3) con:
- Objetivo
- Riesgos
- Criterio de “done”
- PRs pequeños (cada PR: alcance, archivos tocados estimados por ruta, y cómo probar)
Finalmente, PR #1 propuesto en DETALLE:
- Pasos exactos
- Archivos que tocarías (rutas)
- Qué cambiarías y por qué
- Cómo probar (comandos reales)

(8) CRC CARDS: comentarios internos estilo CRC (SIN EDITAR ARCHIVOS)
Proceso:
A) Identificar Top N archivos “críticos” (N=12 aprox.) del backend y frontend:
   - justificar por qué son críticos (entrypoints, core use cases, infra adapters).
B) Mostrar lista de esos archivos con razón (1 línea por archivo).
C) Generar los bloques CRC listos para insertar (por archivo):
   - En TS/React: JSDoc /** ... */
   - En Python: docstring triple quotes
   - Estructura:
     - Name
     - Responsibilities (3–7 bullets)
     - Collaborators
     - Notes/Constraints (invariantes, performance, seguridad, decisiones)
D) Si ves nombres confusos, sugerí renames (NO ejecutar).

SALIDA FINAL
- Cerrá con un resumen ejecutivo:
  - “Qué tan alineado está con nuestra metodología” (porcentaje estimado + justificación)
  - 3 fortalezas principales
  - 3 riesgos principales
  - Próximo paso recomendado (1 acción concreta)
