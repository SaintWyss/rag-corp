# Infrastructure Services Layer

## üéØ Prop√≥sito y Rol en la Arquitectura

Esta carpeta (`infrastructure/services`) contiene la **implementaci√≥n t√©cnica** de los servicios definidos abstractamente en el Dominio.

En **Clean Architecture**, el Dominio define el _qu√©_ ("necesito un embedding", "necesito una respuesta de LLM"), y esta capa define el _c√≥mo_ ("usando la API de Google Gemini", "reintentando si falla", "guardando en cach√©").

Estos servicios act√∫an como **Adapters** (Adaptadores), traduciendo las peticiones de tu aplicaci√≥n al lenguaje de las APIs externas (Google GenAI, etc.).

---

## üß© Componentes Principales

### 1. Servicios de Embeddings (Text $\to$ Vector)

Convierten texto en vectores num√©ricos para b√∫squeda sem√°ntica.

| Archivo                       | Rol             | Descripci√≥n                                                                                                          |
| :---------------------------- | :-------------- | :------------------------------------------------------------------------------------------------------------------- |
| `google_embedding_service.py` | **Adapter**     | Habla directamente con `text-embedding-004` de Google. Maneja _batching_ (lotes de 10) para respetar l√≠mites de API. |
| `cached_embedding_service.py` | **Decorator**   | Envuelve al servicio real. Antes de llamar a Google, mira si ya tiene el vector calculado. Ahorra dinero y latencia. |
| `fake_embedding_service.py`   | **Test Double** | Genera vectores deterministas (hashing) sin llamar a internet. Vital para tests r√°pidos y CI/CD.                     |

**Flujo de Trabajo (Stacking):**

```mermaid
graph LR
    App[Aplicaci√≥n] --> Cache[Cached Service]
    Cache -- Miss --> Retry[Retry Strategy]
    Retry --> Google[Google API]
    Cache -- Hit --> App
```

### 2. Servicios de LLM (Text context $\to$ Answer)

Generan respuestas en lenguaje natural usando modelos de IA generativa.

| Archivo                     | Rol             | Descripci√≥n                                                                                                     |
| :-------------------------- | :-------------- | :-------------------------------------------------------------------------------------------------------------- |
| `llm/google_llm_service.py` | **Adapter**     | Conecta con `gemini-1.5-flash`. Maneja prompts, RAG (Retrieval Augmented Generation) y Streaming de respuestas. |
| `llm/fake_llm.py`           | **Test Double** | Simula respuestas de IA de forma determinista para probar flujos sin gastar tokens.                             |

### 3. Resiliencia y Utilidades

| Archivo       | Rol                | Descripci√≥n                                                                                                                                  |
| :------------ | :----------------- | :------------------------------------------------------------------------------------------------------------------------------------------- |
| `retry.py`    | **Policy/Utility** | Define _cu√°ndo_ y _c√≥mo_ reintentar. Diferencia errores transitorios (reintentar) de permanentes (fallar r√°pido). Usa _Exponential Backoff_. |
| `__init__.py` | **Facade**         | Expone limpiamente los servicios al resto de la app, ocultando la estructura interna de carpetas.                                            |

---

## üõ†Ô∏è Patrones de Dise√±o Implementados

### Adapter Pattern

Todas las clases aqu√≠ implementan interfaces del dominio (`EmbeddingService`, `LLMService`). Esto permite cambiar Google por OpenAI ma√±ana sin tocar una sola l√≠nea de la l√≥gica de negocio.

### Decorator Pattern (`cached_embedding_service.py`)

A√±ade comportamiento (caching) din√°micamente sin modificar el servicio base. La aplicaci√≥n no sabe si est√° hablando con el servicio con cach√© o el directo; la interfaz es id√©ntica.

### Retry Pattern (`retry.py`)

Envuelve llamadas inestables (red) con una pol√≠tica de reintentos inteligente.

- **Exponential Backoff:** Espera 1s, luego 2s, luego 4s... para no saturar al servidor ca√≠do.
- **Jitter:** A√±ade aleatoriedad para evitar "thundering herd" (que todos reintenten al mismo tiempo exacto).

### Deterministic Test Doubles (`fake_*.py`)

En lugar de usar mocks aleatorios, usamos implementaciones falsas pero **deterministas**.

- `hash("Hola")` siempre dar√° el mismo vector `[0.123, ...]`.
- Esto elimina los "Flaky Tests" (pruebas que fallan a veces s√≠, a veces no).

---

## üöÄ Gu√≠a de Uso R√°pido

### Inyecci√≥n de Dependencias

Normalmente no instancias estas clases directamente. El contenedor de dependencias (`apps/backend/app/container.py`) se encarga de ensamblarlas:

```python
# Ejemplo conceptual de ensamblaje
google_service = GoogleEmbeddingService(api_key="...")
caching_service = CachingEmbeddingService(provider=google_service, cache=redis_cache)

# La app recibe el caching_service, pero cree que es un EmbeddingService gen√©rico
use_case = SearchUseCase(embedding_service=caching_service)
```

### Cu√°ndo crear un nuevo servicio

- **Nuevo Proveedor:** Crea `openai_embedding_service.py` implementando `EmbeddingService`.
- **Nueva L√≥gica:** Si necesitas filtrar malas palabras, crea un `ModerationDecorator` que envuelva al servicio.
