# Text (chunking)

Como una **m√°quina cortadora**: toma texto crudo y lo corta en fragmentos estables, con overlap y metadata, para que luego se embeba e indexe.

## üéØ Misi√≥n

Este m√≥dulo provee utilidades de **chunking determin√≠stico** usadas durante la ingesta. Convierte texto plano en una lista de chunks (strings) o en fragmentos enriquecidos (`ChunkFragment`) con offsets y metadata m√≠nima.

Su objetivo es que el pipeline de ingesta tenga un paso de fragmentaci√≥n:

- predecible (mismo input ‚Üí mismo output),
- defensivo (l√≠mites y saneo),
- f√°cil de testear,
- extensible con variantes (sem√°ntico/estructurado) sin romper el baseline.

Recorridos r√°pidos por intenci√≥n:

- **Quiero el chunking base (tama√±o + overlap, estable)** ‚Üí `chunker.py` (`chunk_text`, `chunk_fragments`)
- **Quiero fragmentos con offsets y metadatos** ‚Üí `models.py` (`ChunkFragment`)
- **Quiero heur√≠sticas ‚Äúsem√°nticas‚Äù (cortes por puntuaci√≥n/pausas)** ‚Üí `semantic_chunker.py`
- **Quiero respetar estructura (secciones/t√≠tulos)** ‚Üí `structured_chunker.py`
- **Quiero ver c√≥mo se usa en el pipeline de ingesta** ‚Üí `../../application/usecases/ingestion/process_uploaded_document.py`

### Qu√© S√ç hace

- Parte texto en chunks con **overlap** configurable.
- Normaliza/sanea texto (m√≠nimo) para evitar chunks vac√≠os o ruido.
- Expone modelos de fragmentos (`ChunkFragment`) con offsets y campos de metadata b√°sicos.
- Ofrece variantes de chunking:
  - **Sem√°ntico:** heur√≠sticas de corte para evitar cortar oraciones en lugares ‚Äúfeos‚Äù.
  - **Estructurado:** respeta secciones para mantener contexto por bloque.

### Qu√© NO hace (y por qu√©)

- No genera embeddings.
  - **Raz√≥n:** embeddings es IO externo (otro subsistema) y se gobierna desde Application.
  - **Impacto:** el output de chunking se pasa al `EmbeddingService` aguas abajo.

- No accede a storage ni DB.
  - **Raz√≥n:** este m√≥dulo debe ser puro y r√°pido.
  - **Impacto:** no sabe `document_id` ni guarda resultados; solo devuelve fragmentos.

- No aplica pol√≠ticas de negocio.
  - **Raz√≥n:** permisos/visibilidad se resuelven antes (workspace policy).
  - **Impacto:** no filtra por actor ni workspace; opera sobre texto ya autorizado.

## üó∫Ô∏è Mapa del territorio

| Recurso                 | Tipo           | Responsabilidad (en humano)                                                                                   |
| :---------------------- | :------------- | :------------------------------------------------------------------------------------------------------------ |
| `__init__.py`           | Archivo Python | Exporta funciones y modelos de chunking para imports estables.                                                |
| `chunker.py`            | Archivo Python | Chunking base: divide por tama√±o y aplica overlap con reglas defensivas (no vac√≠o, merge de cola).            |
| `models.py`             | Archivo Python | Modelo `ChunkFragment`: texto, offsets, √≠ndice, longitud y metadata m√≠nima del fragmento.                     |
| `semantic_chunker.py`   | Archivo Python | Chunker con heur√≠sticas sem√°nticas: pre-corte por separadores (puntos, saltos) y luego aplica tama√±o/overlap. |
| `structured_chunker.py` | Archivo Python | Chunker estructurado: respeta secciones (t√≠tulos/bloques) y produce fragmentos con metadata de secci√≥n.       |
| `README.md`             | Documento      | Portada + navegaci√≥n y contratos del m√≥dulo.                                                                  |

## ‚öôÔ∏è ¬øC√≥mo funciona por dentro?

### Conceptos m√≠nimos (en contexto)

- **Chunk size:** tama√±o objetivo del fragmento (caracteres o tokens aproximados, seg√∫n implementaci√≥n). Aqu√≠ se trabaja sobre texto plano, as√≠ que el tama√±o es **por caracteres**.
- **Overlap:** solapamiento entre chunks consecutivos para no perder contexto en los bordes. Ej: chunk_size=1000, overlap=200 ‚Üí cada chunk comparte los √∫ltimos 200 caracteres con el siguiente.
- **Offsets:** posiciones (start/end) respecto del texto original para trazabilidad (auditor√≠a, debugging, highlight en UI).

### 1) `chunk_text` (compatibilidad)

**Input**

- `text: str`, `chunk_size: int`, `overlap: int`.

**Proceso**

1. Sanitiza el input:
   - `text.strip()`; si queda vac√≠o ‚Üí devuelve `[]`.
   - colapsa whitespace extremo (si aplica en helper interno).

2. Valida l√≠mites defensivos:
   - `chunk_size` m√≠nimo razonable (ej. > 0).
   - `overlap` se acota a `[0, chunk_size - 1]` (evita loops).

3. Itera sobre ventanas del texto:
   - start = 0
   - end = min(start + chunk_size, len(text))
   - slice = text[start:end]

4. Avanza con overlap:
   - next_start = max(end - overlap, 0)
   - si `next_start` no avanza (por par√°metros malos), se corta.

5. Tail merge (si aplica):
   - si el √∫ltimo chunk queda demasiado corto (p. ej. < 30% de `chunk_size`), se mergea al anterior.

**Output**

- `list[str]` con chunks en orden.

### 2) `chunk_fragments` (fragmentos enriquecidos)

**Input**

- `text: str`, `chunk_size`, `overlap`.

**Proceso**

- Reutiliza el mismo algoritmo base, pero en vez de devolver strings:
  - construye `ChunkFragment(index=i, start_offset=start, end_offset=end, text=slice, metadata={...})`.

- Metadata t√≠pica:
  - `{"source": "plain", "overlap": overlap, "chunk_size": chunk_size}`.

**Output**

- `list[ChunkFragment]`.

### 3) Chunker sem√°ntico (`semantic_chunker.py`)

**Objetivo:** minimizar cortes ‚Äúantinaturales‚Äù (p. ej. partir una oraci√≥n por la mitad).

**Input**

- texto plano + par√°metros de tama√±o.

**Proceso**

1. Pre-segmenta por separadores fuertes:
   - saltos de l√≠nea dobles, t√≠tulos simples, puntos finales, etc.

2. Agrupa segmentos hasta aproximar `chunk_size`.
3. Si un segmento excede `chunk_size`, cae al algoritmo base (split duro) para no romper l√≠mites.
4. Aplica overlap entre grupos resultantes.

**Output**

- `list[str]` o `list[ChunkFragment]` (seg√∫n helper expuesto).

### 4) Chunker estructurado (`structured_chunker.py`)

**Objetivo:** preservar estructura (por ejemplo, secciones) para que el embedding mantenga contexto jer√°rquico.

**Input**

- texto + heur√≠stica de secciones (p. ej. headings, separadores).

**Proceso**

1. Detecta l√≠mites de secciones.
2. Para cada secci√≥n:
   - genera chunks internos (size/overlap).
   - agrega metadata: `section_title`, `section_index`, `path`.

3. Emite fragmentos con offsets globales (respecto al texto completo) y metadata por secci√≥n.

**Output**

- `list[ChunkFragment]` con metadata estructural.

## üîó Conexiones y roles

- **Rol arquitect√≥nico:** _Infrastructure_ (text processing puro, sin IO).

- **Recibe √≥rdenes de:**
  - Use cases de ingesta (`application/usecases/ingestion/process_uploaded_document.py`, `ingest_document.py`).

- **Llama a:**
  - Ninguna dependencia externa. Solo Python est√°ndar.

- **Reglas de l√≠mites (imports/ownership):**
  - No importa repositorios ni storage.
  - No importa servicios de embeddings/LLM.
  - No conoce `workspace_id` ni permisos.

## üë©‚Äçüíª Gu√≠a de uso (Snippets)

### 1) Chunking base (strings)

```python
from app.infrastructure.text.chunker import chunk_text

chunks = chunk_text(
    "Hola mundo. Esto es una prueba.",
    chunk_size=20,
    overlap=5,
)
print(chunks)
```

### 2) Fragmentos con offsets (para trazabilidad)

```python
from app.infrastructure.text.chunker import chunk_fragments

fragments = chunk_fragments(
    "Hola mundo. Esto es una prueba.",
    chunk_size=20,
    overlap=5,
)

for f in fragments:
    print(f.index, f.start_offset, f.end_offset, f.text)
```

### 3) Sem√°ntico (mejor cortes por oraciones)

```python
from app.infrastructure.text.semantic_chunker import semantic_chunk_text

chunks = semantic_chunk_text(
    "Linea 1. Linea 2.\n\nTitulo\nContenido largo...",
    chunk_size=500,
    overlap=100,
)
print(len(chunks))
```

### 4) Estructurado (secciones + metadata)

```python
from app.infrastructure.text.structured_chunker import structured_chunk_fragments

fragments = structured_chunk_fragments(
    "# Intro\nTexto...\n\n# Detalles\nMas texto...",
    chunk_size=800,
    overlap=120,
)

for f in fragments:
    print(f.metadata.get("section_title"), f.index)
```

## üß© C√≥mo extender sin romper nada

Checklist pr√°ctico:

1. **Mantener baseline estable**
   - `chunk_text` y `chunk_fragments` son el contrato m√≠nimo.
   - Un chunker nuevo no debe cambiar el output del baseline.

2. **Agregar un chunker nuevo**
   - Crear `my_chunker.py`.
   - Exponer una funci√≥n `my_chunk_text(...)` o `my_chunk_fragments(...)`.
   - Mantener firma compatible: `text`, `chunk_size`, `overlap`, y par√°metros opcionales con defaults.

3. **Defensivo por default**
   - Acotar `overlap` para evitar loops (`overlap < chunk_size`).
   - Evitar chunks vac√≠os.
   - Aplicar tail-merge cuando el √∫ltimo fragmento quede demasiado chico.

4. **Metadata m√≠nima y estable**
   - Si agreg√°s metadata, mantenela chica (evita payloads grandes en DB).
   - No guardes texto duplicado innecesario.

5. **Tests obligatorios**
   - entradas vac√≠as / whitespace.
   - textos muy largos (performance) y par√°metros extremos.
   - `chunk_size` peque√±o, `overlap` grande.
   - consistencia de offsets (no solaparse mal, end>=start, orden creciente).

## üÜò Troubleshooting

1. **Se generan demasiados chunks**

- Causa probable: `chunk_size` demasiado bajo o el texto tiene muchos separadores.
- D√≥nde mirar: par√°metros del pipeline (settings de ingesta) y `semantic_chunker.py` (pre-segmentaci√≥n).
- Soluci√≥n: subir `chunk_size` o bajar heur√≠sticas de separaci√≥n.

2. **Chuncks con overlap ‚Äúinfinito‚Äù / loop**

- Causa probable: `overlap >= chunk_size`.
- D√≥nde mirar: validaci√≥n defensiva en `chunker.py`.
- Soluci√≥n: acotar `overlap` o fallar fail-fast.

3. **Chunks muy cortos al final**

- Causa probable: tail-merge desactivado o umbral demasiado bajo.
- D√≥nde mirar: regla de tail-merge en `chunker.py`.
- Soluci√≥n: activar merge o ajustar el threshold.

4. **Offsets incorrectos (UI resalta mal)**

- Causa probable: normalizaci√≥n de texto previa que cambia longitud sin actualizar offsets.
- D√≥nde mirar: saneo/normalizaci√≥n en `chunker.py`.
- Soluci√≥n: si normaliz√°s, hacelo antes y manten√© offsets sobre el texto final; o guard√° mapping expl√≠cito.

5. **Chunker sem√°ntico corta ‚Äúraro‚Äù**

- Causa probable: heur√≠stica de separadores demasiado agresiva.
- D√≥nde mirar: lista de separadores y agrupamiento en `semantic_chunker.py`.
- Soluci√≥n: ajustar separadores, aumentar `chunk_size` o agregar fallback m√°s temprano.

6. **Chunker estructurado pierde t√≠tulos**

- Causa probable: el detector de secciones no reconoce el formato (Markdown/HTML).
- D√≥nde mirar: parsing simple en `structured_chunker.py`.
- Soluci√≥n: extender detectores (ej. `##`, n√∫meros, may√∫sculas) y agregar tests por formato.

## üîé Ver tambi√©n

- `../../application/usecases/ingestion/README.md` (pipeline de ingesta)
- `../../application/usecases/ingestion/process_uploaded_document.py` (d√≥nde se llama al chunker)
- `../services/README.md` (embeddings y caching, paso siguiente del pipeline)
- `../repositories/postgres/README.md` (persistencia de chunks y b√∫squeda vectorial)
- `../../domain/services.py` (puertos consumidos por Application: embeddings/LLM)
