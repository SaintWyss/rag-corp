# Storage (S3/MinIO)

Como un **dep√≥sito de archivos**: guarda y sirve binarios fuera de la DB, con URLs firmadas para descargar sin pasar por el backend.

## üéØ Misi√≥n

Este m√≥dulo implementa el adaptador de almacenamiento de archivos sobre un backend **S3-compatible** (AWS S3 / MinIO). Expone una API estable (puerto `FileStoragePort`) para que los casos de uso suban/descarguen/borran archivos sin conocer `boto3` ni detalles del proveedor.

Recorridos r√°pidos por intenci√≥n:

- **Quiero subir un archivo durante la ingesta** ‚Üí `s3_file_storage.py` (`upload_file`) usado por `application/usecases/ingestion/upload_document.py`.
- **Quiero descargar el archivo para extraer texto** ‚Üí `s3_file_storage.py` (`download_file`) usado por `application/usecases/ingestion/process_uploaded_document.py`.
- **Quiero borrar hu√©rfanos ante fallas de DB** ‚Üí `s3_file_storage.py` (`delete_file`) desde el rollback en `upload_document.py`.
- **Quiero entregar descarga directa al cliente** ‚Üí `s3_file_storage.py` (`generate_presigned_url`).
- **Quiero entender errores y c√≥mo se tipan** ‚Üí `errors.py`.

### Qu√© S√ç hace

- Sube objetos al bucket (`put_object` o `upload_fileobj`).
- Descarga objetos a memoria (`get_object` + `Body.read()`).
- Elimina objetos (`delete_object`).
- Genera URLs presignadas para descarga (`generate_presigned_url`).
- Traduce fallas del SDK a errores tipados del subsistema (`StorageError` y derivados), sin filtrar excepciones de vendor.

### Qu√© NO hace (y por qu√©)

- No guarda metadata de documentos.
  - **Raz√≥n:** la metadata vive en repositorios (DB) y se gobierna desde Application.
  - **Impacto:** este adaptador no sabe `document_id`, `workspace_id`, estado ni tags; solo trabaja con `key`.

- No expone endpoints HTTP.
  - **Raz√≥n:** el transporte pertenece a _Interfaces_.
  - **Impacto:** si se necesita un endpoint para ‚Äúdescargar‚Äù, Interfaces genera una presigned URL o delega a un caso de uso que la genere.

- No implementa autorizaci√≥n/ACL.
  - **Raz√≥n:** la autorizaci√≥n se decide en Domain/Application.
  - **Impacto:** si se llama a storage con una key indebida, el adapter no puede ‚Äúvalidar permisos‚Äù; solo ejecuta la operaci√≥n.

## üó∫Ô∏è Mapa del territorio

| Recurso              | Tipo           | Responsabilidad (en humano)                                                                                         |
| :------------------- | :------------- | :------------------------------------------------------------------------------------------------------------------ |
| `__init__.py`        | Archivo Python | Exporta el adapter y la jerarqu√≠a de errores para imports estables desde `app.container`.                           |
| `errors.py`          | Archivo Python | Define `StorageError` y subclases (`Configuration/NotFound/Permission/Unavailable`) para manejo consistente arriba. |
| `s3_file_storage.py` | Archivo Python | Implementa `FileStoragePort` contra S3/MinIO: upload (bytes/stream), download (bytes), delete e URLs presignadas.   |
| `README.md`          | Documento      | Portada + gu√≠a de navegaci√≥n y contratos de este subsistema.                                                        |

## ‚öôÔ∏è ¬øC√≥mo funciona por dentro?

### 1) Configuraci√≥n y construcci√≥n del cliente

- **Input:** `S3Config(bucket, access_key, secret_key, region?, endpoint_url?)`.
- **Proceso:**
  1. `S3FileStorageAdapter.__init__` valida fail-fast:
     - `bucket` no vac√≠o.
     - `access_key/secret_key` no vac√≠os.

  2. Cliente inyectable para tests:
     - si se pasa `client=...`, se usa tal cual.

  3. Lazy import:
     - si no hay `client`, importa `boto3` dentro del constructor.
     - si `boto3` no est√° instalado ‚Üí `StorageConfigurationError("boto3 no est√° instalado.")`.

  4. Construye `boto3.client('s3', aws_access_key_id=..., aws_secret_access_key=..., region_name=..., endpoint_url=...)`.

**Por qu√© as√≠:**

- Validaci√≥n fail-fast evita correr en runtime con config incompleta.
- Lazy import reduce costo de arranque y evita dependencia dura en import-time.
- Cliente inyectable permite tests unitarios sin red y sin credenciales.

### 2) Upload (`upload_file`)

- **Input:** `key: str`, `content: bytes | BinaryIO`, `content_type: str | None`.
- **Proceso:**
  1. `_require_key(key)` (si est√° vac√≠o ‚Üí `StorageError("key de storage es requerido.")`).
  2. Normaliza `ContentType`:
     - si `content_type` es `None`, usa `application/octet-stream`.

  3. Rama seg√∫n tipo de `content`:
     - **bytes/bytearray/memoryview** ‚Üí `put_object(Bucket, Key, Body, ContentType)`.
     - **stream (BinaryIO)** ‚Üí `upload_fileobj(Fileobj, Bucket, Key, ExtraArgs={'ContentType': ...})`.

  4. Cualquier excepci√≥n se mapea con `_map_storage_error(exc, action='upload', key=...)`.

**Detalle importante:**

- La rama de stream existe para evitar OOM con archivos grandes. El puerto hoy permite pasar `BinaryIO`, aunque algunos casos de uso usen bytes.

### 3) Download (`download_file`)

- **Input:** `key: str`.
- **Proceso:**
  1. `get_object(Bucket, Key)`.
  2. `Body.read()` a memoria.
  3. cierre best-effort del body.
  4. mapeo de errores v√≠a `_map_storage_error(action='download')`.

**Trade-off:**

- El port devuelve `bytes`; si en el futuro quer√©s streaming real, eso implicar√≠a extender el port (p. ej. `download_stream`).

### 4) Delete (`delete_file`)

- **Input:** `key: str`.
- **Proceso:** `delete_object(Bucket, Key)`.

**Dise√±o:**

- El delete en S3 suele ser idempotente: borrar una key inexistente no deber√≠a romper un flujo de cleanup.
- Si hay un error real (permiso/infra), se tipa y se eleva.

### 5) Presigned URL (`generate_presigned_url`)

- **Input:** `key: str`, `expires_in_seconds=3600`, `filename: str | None`.
- **Proceso:**
  1. `_require_key(key)`.
  2. sanitiza `expires_in_seconds` (si ‚â§ 0, usa 3600).
  3. arma `Params={'Bucket': ..., 'Key': ...}`.
  4. si `filename` est√° presente:
     - agrega `ResponseContentDisposition='attachment; filename="..."'` (escapa comillas).

  5. llama `generate_presigned_url(ClientMethod='get_object', Params=params, ExpiresIn=...)`.
  6. errores mapeados con `_map_storage_error(action='presign')`.

### 6) Mapeo de errores (`_map_storage_error`)

Este adapter no filtra `botocore.exceptions`. Las traduce a un lenguaje de storage:

- **Unavailable (infra/red):**
  - `EndpointConnectionError`, `ConnectTimeoutError`, `ReadTimeoutError` ‚Üí `StorageUnavailableError("timeout/conexi√≥n")`.

- **ClientError (S3 estructurado):**
  - `NoSuchKey` / `404` / `NotFound` ‚Üí `StorageNotFoundError(key)`.
  - `AccessDenied` / `InvalidAccessKeyId` / `SignatureDoesNotMatch` ‚Üí `StoragePermissionError(...)`.
  - `SlowDown` / `RequestTimeout` / `ServiceUnavailable` ‚Üí `StorageUnavailableError(...)`.
  - otros c√≥digos ‚Üí `StorageError(f"Fallo de storage ({action}). code={code}")`.

- **Fallback:** cualquier otra excepci√≥n ‚Üí `StorageError(f"Fallo de storage ({action}).")`.

Observabilidad:

- En fallas de infra (timeouts), loguea `warning` con `action` y `key`.
- En `ClientError` desconocido o fallback gen√©rico, loguea `exception` con contexto.

## üîó Conexiones y roles

- **Rol arquitect√≥nico:** _Infrastructure_ (adapter de IO / almacenamiento).

- **Recibe √≥rdenes de:**
  - Casos de uso en `application/` (ingestion, downloads, cleanup), v√≠a el puerto `FileStoragePort`.

- **Llama a:**
  - `boto3` / `botocore` (SDK S3) encapsulado dentro del adapter.

- **Reglas de l√≠mites (imports/ownership):**
  - No importa FastAPI ni DTOs HTTP.
  - No conoce repositorios, estados de documento ni ACL.
  - No expone tipos de vendor (no se filtran `ClientError`/`EndpointConnectionError` hacia arriba).

Wiring en el container:

- `app/container.py:get_file_storage()` construye este adapter **solo si** est√°n seteados:
  - `Settings.s3_bucket`
  - `Settings.s3_access_key`
  - `Settings.s3_secret_key`
  - opcional: `Settings.s3_region`, `Settings.s3_endpoint_url`

- Si falta algo requerido, devuelve `None` y los casos de uso deben tratarlo como `SERVICE_UNAVAILABLE`.

## üë©‚Äçüíª Gu√≠a de uso (Snippets)

### 1) Runtime: obtener storage desde el container

```python
from app.container import get_file_storage

storage = get_file_storage()  # FileStoragePort | None
if storage is None:
    raise RuntimeError("Storage no configurado")

storage.upload_file("documents/123/manual.pdf", b"%PDF-...", "application/pdf")
```

### 2) Crear el adapter expl√≠citamente (MinIO local)

```python
from app.infrastructure.storage import S3Config, S3FileStorageAdapter

storage = S3FileStorageAdapter(
    S3Config(
        bucket="rag-docs",
        access_key="minioadmin",
        secret_key="minioadmin",
        region=None,
        endpoint_url="http://localhost:9000",
    )
)

storage.upload_file("docs/example.txt", b"hola", "text/plain")
```

### 3) Upload por stream (evita OOM en archivos grandes)

```python
from pathlib import Path

from app.infrastructure.storage import S3Config, S3FileStorageAdapter

storage = S3FileStorageAdapter(
    S3Config(bucket="rag-docs", access_key="...", secret_key="...", endpoint_url="http://localhost:9000")
)

with Path("./manual.pdf").open("rb") as f:
    storage.upload_file(
        "documents/123/manual.pdf",
        f,  # BinaryIO
        "application/pdf",
    )
```

### 4) Presigned URL con nombre sugerido

```python
from app.container import get_file_storage

storage = get_file_storage()
if storage is None:
    raise RuntimeError("Storage no configurado")

url = storage.generate_presigned_url(
    "documents/123/manual.pdf",
    expires_in_seconds=600,
    filename="manual.pdf",
)
print(url)
```

## üß© C√≥mo extender sin romper nada

Checklist pr√°ctico:

1. **Nuevo backend** (ej. filesystem local para dev):
   - implementar el puerto `FileStoragePort` con la misma sem√°ntica (`upload_file/download_file/delete_file/generate_presigned_url`).
   - tipar errores en el mismo lenguaje (`StorageError` y subclases), sin filtrar excepciones de vendor.

2. **Mantener guardrails**:
   - `_require_key` o equivalente: no aceptar keys vac√≠as.
   - `content_type` default a `application/octet-stream`.
   - upload debe soportar bytes y, si es posible, stream para archivos grandes.

3. **Extender capacidades** (si hace falta streaming real):
   - agregar un m√©todo nuevo al port (ej. `download_stream`) en `domain.services.FileStoragePort`.
   - implementar en `S3FileStorageAdapter` sin romper compatibilidad (mantener `download_file`).

4. **Wiring**:
   - exponer el nuevo adapter en `infrastructure/storage/__init__.py`.
   - seleccionar el backend en `app/container.py` por settings/flag (sin l√≥gica de negocio).

5. **Tests**:
   - unit: inyectar `client` mockeado para forzar ramas de error y mapping.
   - integration: levantar MinIO y validar upload/download/presign con credenciales de dev.

## üÜò Troubleshooting

1. **`StorageConfigurationError: S3 bucket es requerido.`**

- Causa probable: `Settings.s3_bucket` vac√≠o.
- D√≥nde mirar: `app/container.py:get_file_storage()` y `S3FileStorageAdapter.__init__`.
- Soluci√≥n: setear `s3_bucket` y reiniciar.

2. **`StorageConfigurationError: Credenciales S3 requeridas`**

- Causa probable: faltan `s3_access_key` o `s3_secret_key`.
- D√≥nde mirar: `app/container.py:get_file_storage()`.
- Soluci√≥n: setear credenciales en env/settings.

3. **`StorageConfigurationError: boto3 no est√° instalado.`**

- Causa probable: entorno sin dependencia.
- D√≥nde mirar: `s3_file_storage.py` (lazy import de boto3).
- Soluci√≥n: instalar dependencias del backend o asegurar el extra correspondiente.

4. **`StorageNotFoundError` al descargar**

- Causa probable: key inexistente o mal formada.
- D√≥nde mirar: `storage_key` persistida en DB (repos) y c√≥mo se construye en `upload_document.py`.
- Soluci√≥n: verificar key en metadata del documento y el bucket correcto.

5. **`StoragePermissionError` (AccessDenied / SignatureDoesNotMatch)**

- Causa probable: credenciales inv√°lidas o policy del bucket.
- D√≥nde mirar: configuraci√≥n (keys) y logs del adapter (action/key).
- Soluci√≥n: corregir credenciales; validar que el usuario tenga permisos `s3:GetObject/PutObject/DeleteObject`.

6. **`StorageUnavailableError` (timeout/conexi√≥n)**

- Causa probable: `endpoint_url` incorrecto, MinIO ca√≠do o red.
- D√≥nde mirar: settings `s3_endpoint_url` y logs `Storage unavailable`.
- Soluci√≥n: corregir endpoint, verificar conectividad y health del servicio.

7. **Presigned URL no descarga / descarga con nombre raro**

- Causa probable: `filename` con caracteres conflictivos o `ContentDisposition` no respetado.
- D√≥nde mirar: `generate_presigned_url` (sanitiza comillas).
- Soluci√≥n: pasar `filename` simple; si necesit√°s i18n, extender sanitizaci√≥n/encoding.

8. **Rollback deja archivos hu√©rfanos**

- Causa probable: falla de DB + falla de delete durante cleanup.
- D√≥nde mirar: `application/usecases/ingestion/upload_document.py` (`_cleanup_orphaned_file`).
- Soluci√≥n: revisar logs de delete; ejecutar limpieza manual o sumar job de garbage collection.

## üîé Ver tambi√©n

- `../../domain/services.py` (puerto `FileStoragePort`)
- `../../container.py` (`get_file_storage` y settings `s3_*`)
- `../../application/usecases/ingestion/upload_document.py` (upload + rollback de hu√©rfanos)
- `../../application/usecases/ingestion/process_uploaded_document.py` (download para extracci√≥n)
- `../repositories/postgres/README.md` (metadata en DB; storage solo binarios)
