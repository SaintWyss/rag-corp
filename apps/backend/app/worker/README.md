# worker

Como un **taller**: consume jobs de RQ y ejecuta tareas pesadas fuera de la API, con health/ready/metrics propios.

## üéØ Misi√≥n

Este m√≥dulo implementa el **runtime del worker** basado en RQ: levanta un proceso que consume jobs desde Redis (por ejemplo, procesamiento de documentos) y expone endpoints livianos para **health**, **readiness** y **metrics**.

Recorridos r√°pidos por intenci√≥n:

- **Quiero ver qu√© jobs existen y c√≥mo se invocan** ‚Üí `jobs.py`
- **Quiero entender c√≥mo arranca y consume la cola** ‚Üí `worker.py`
- **Quiero diagnosticar DB/Redis** ‚Üí `worker_health.py` y endpoints `/healthz`/`/readyz`
- **Quiero ver el server HTTP de observabilidad** ‚Üí `worker_server.py`
- **Quiero ver el pipeline que ejecuta** ‚Üí `../application/usecases/ingestion/README.md`

### Qu√© S√ç hace

- Consume jobs de RQ (Redis) y ejecuta entrypoints definidos en `jobs.py`.
- Inicializa dependencias runtime necesarias en el proceso worker (Redis + pool de DB).
- Expone un HTTP server m√≠nimo para `/healthz`, `/readyz` y `/metrics`.
- Orquesta casos de uso (Application) sin meter reglas de negocio dentro del worker.

### Qu√© NO hace (y por qu√©)

- No expone la API HTTP de negocio.
  - **Raz√≥n:** la API vive en _Interfaces_ (routers FastAPI).
  - **Impacto:** este m√≥dulo solo sirve observabilidad del worker; no maneja endpoints de producto.

- No contiene reglas de negocio.
  - **Raz√≥n:** la l√≥gica pertenece a _Application/Domain_.
  - **Impacto:** agregar un job nuevo implica delegar a un use case (y cablear en el container), no escribir l√≥gica ad‚Äëhoc ac√°.

## üó∫Ô∏è Mapa del territorio

| Recurso            | Tipo           | Responsabilidad (en humano)                                                                |
| :----------------- | :------------- | :----------------------------------------------------------------------------------------- |
| `jobs.py`          | Archivo Python | Entrypoints de jobs RQ: validan inputs serializables y delegan a casos de uso.             |
| `worker.py`        | Archivo Python | Entrypoint del proceso worker: configura conexi√≥n Redis, crea `rq.Worker` y entra al loop. |
| `worker_health.py` | Archivo Python | Checks de DB/Redis para readiness; arma payloads de diagn√≥stico simples.                   |
| `worker_server.py` | Archivo Python | HTTP server m√≠nimo para `/healthz`, `/readyz` y `/metrics` (observabilidad).               |
| `README.md`        | Documento      | Portada + gu√≠a de navegaci√≥n del runtime del worker.                                       |

## ‚öôÔ∏è ¬øC√≥mo funciona por dentro?

Input ‚Üí Proceso ‚Üí Output, con pasos reales del runtime.

### 1) Consumo de jobs (RQ)

- **Input:** un job en Redis con par√°metros serializables (generalmente strings): `document_id`, `workspace_id`.
- **Proceso:**
  1. `worker.py` lee settings (ej. `REDIS_URL`, `DATABASE_URL`).
  2. Inicializa Redis client/connection usada por RQ.
  3. Inicializa el pool/conexi√≥n de DB para que los jobs puedan persistir estado.
  4. Crea `rq.Worker(queues=...)` y comienza el loop de consumo.
  5. Al ejecutar un job, RQ llama la funci√≥n definida en `jobs.py`.

### 2) Ejecuci√≥n de un job (ej. procesamiento de documento)

- **Input:** `process_document_job(document_id: str, workspace_id: str, ...)`.
- **Proceso:**
  1. `jobs.py` valida/partea UUIDs (fail‚Äëfast).
  2. Construye el caso de uso v√≠a `app.container` (inyecci√≥n de puertos/servicios).
  3. Ejecuta `ProcessUploadedDocumentUseCase.execute(...)`.
  4. El use case actualiza status del documento y persiste chunks/embeddings.
  5. Registra m√©tricas (si est√°n habilitadas).

- **Output:**
  - Cambios persistidos (status/chunks/embeddings) y logs/metrics del job.

### 3) Observabilidad del worker (HTTP liviano)

- **Input:** request HTTP a `/healthz`, `/readyz` o `/metrics`.
- **Proceso:** `worker_server.py` responde con payloads simples:
  - `/healthz`: proceso vivo.
  - `/readyz`: DB + Redis OK (usa `worker_health.py`).
  - `/metrics`: m√©tricas (si est√°n habilitadas y autorizadas).

- **Output:** status code + body JSON/text.

Conceptos en contexto:

- **RQ:** cola simple sobre Redis; serializa par√°metros del job.
- **Readiness:** ‚Äúpuedo trabajar‚Äù (dependencias listas), distinto de ‚Äúestoy vivo‚Äù.

## üîó Conexiones y roles

- **Rol arquitect√≥nico:** Operational runtime / Infrastructure adapter (ejecuci√≥n de jobs).

- **Recibe √≥rdenes de:**
  - Redis/RQ (jobs encolados).

- **Llama a:**
  - Application: `app/application/usecases/ingestion` (pipeline real).
  - Composition: `app/container.py` (builders / dependencias).
  - Infrastructure: repositorios, storage, embeddings, extractores (inyectados).
  - Crosscutting: m√©tricas/logs/config.

- **Reglas de l√≠mites (contratos):**
  - Los jobs reciben solo tipos serializables (strings, ints, bools).
  - Ning√∫n job implementa negocio: delega a un use case.
  - Los paths de jobs deben ser estables para el enqueuer (ver `job_paths.py`).

## üë©‚Äçüíª Gu√≠a de uso (Snippets)

### 1) Readiness payload (sanity check)

```python
from app.worker.worker_health import readiness_payload

status = readiness_payload()
assert "db" in status and "redis" in status
```

### 2) Ejecutar un job manualmente (debug local)

```python
from uuid import UUID

from app.worker.jobs import process_document_job

process_document_job(
    document_id=str(UUID("22222222-2222-2222-2222-222222222222")),
    workspace_id=str(UUID("00000000-0000-0000-0000-000000000000")),
)
```

### 3) Levantar el server HTTP del worker (health/metrics)

```python
from app.worker.worker_server import serve

serve(host="0.0.0.0", port=8081)
```

### 4) Patr√≥n de enqueue (desde infraestructura)

```python
# Nota: el enqueue se implementa en el adapter de cola (infra).
# Este snippet ilustra el contrato: job path estable + args serializables.

job_path = "app.worker.jobs.process_document_job"
args = {"document_id": "...", "workspace_id": "..."}
```

## üß© C√≥mo extender sin romper nada

Checklist pr√°ctico:

1. **Defin√≠ un nuevo job** en `jobs.py`:
   - firma simple: solo strings/ints/bools.
   - validaci√≥n fail‚Äëfast (parseo de UUIDs, rangos, etc.).

2. **Deleg√° a Application**:
   - constru√≠ el use case v√≠a `app.container`.
   - no metas negocio ni queries SQL ac√°.

3. **Registr√° el path estable**:
   - agregalo en `app/infrastructure/queue/job_paths.py` para que el enqueuer no dependa de imports fr√°giles.

4. **Observabilidad**:
   - logs y m√©tricas best‚Äëeffort, sin romper el job si el exporter falla.

5. **Tests**:
   - unit: job valida inputs y llama al use case (mock).
   - integration: job completo con Redis/DB si el repo tiene suite.

## üÜò Troubleshooting

- **Worker no inicia** ‚Üí `REDIS_URL` faltante o inv√°lida ‚Üí revisar `worker.py` y `.env` ‚Üí validar conectividad a Redis.
- **`/readyz` devuelve `db: disconnected`** ‚Üí `DATABASE_URL` inv√°lida / DB ca√≠da ‚Üí revisar `.env` + logs ‚Üí probar conexi√≥n desde el contenedor.
- **`/readyz` devuelve `redis: disconnected`** ‚Üí Redis inaccesible / credenciales ‚Üí revisar `REDIS_URL` y red docker.
- **Jobs en cola pero no se consumen** ‚Üí worker no est√° escuchando la misma queue ‚Üí revisar nombre de queue en `worker.py` y en el enqueue.
- **Job falla por UUID inv√°lido** ‚Üí el enqueuer envi√≥ strings mal formadas ‚Üí revisar adapter de cola y `job_paths.py`.
- **`/metrics` devuelve 403** ‚Üí auth de m√©tricas habilitada ‚Üí revisar setting `metrics_require_auth` en config/crosscutting.

## üîé Ver tambi√©n

- `../application/usecases/ingestion/README.md` (pipeline que ejecutan los jobs)
- `../infrastructure/queue/README.md` (adapter de cola y enqueue)
- `../crosscutting/README.md` (m√©tricas/logs/tracing)
- `../crosscutting/metrics.py` (m√©tricas espec√≠ficas)
